{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d962873",
   "metadata": {},
   "source": [
    "### Plots notebook\n",
    "Generates Violin- and Scatterplots\n",
    "Output: `output_394/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a84407",
   "metadata": {},
   "source": [
    "#### Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8061ead4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:52: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: {\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:71: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:202: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `scale` parameter has been renamed and will be removed in v0.15.0. Pass `density_norm='width'` for the same effect.\n",
      "  sns.violinplot(\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/1071554932.py:270: FutureWarning: \n",
      "\n",
      "The `bw` parameter is deprecated in favor of `bw_method`/`bw_adjust`.\n",
      "Setting `bw_method=0.2`, but please see docs for the new parameters\n",
      "and update your code. This will become an error in seaborn v0.15.0.\n",
      "\n",
      "  sns.violinplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All plots have been generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql://cosea_user:CoSeaIndex@pgsql.dataconn.net:5432/cosea_db\"\n",
    ")\n",
    "\n",
    "# Load school data\n",
    "school_df = pd.read_sql('SELECT * FROM \"allhsgrades24\".tbl_approvedschools', engine)\n",
    "school_df.columns = school_df.columns.str.lower()\n",
    "\n",
    "# Load RI columns\n",
    "ri_df = pd.read_sql(\n",
    "    'SELECT \"UNIQUESCHOOLID\", \"RI_White\", \"RI_Black\", \"RI_Asian\", \"RI_Hispanic\" '\n",
    "    'FROM census.gadoe2024_389',\n",
    "    engine\n",
    ")\n",
    "ri_df.columns = ri_df.columns.str.lower()\n",
    "school_metrics = school_df.merge(ri_df, on=\"uniqueschoolid\", how=\"left\")\n",
    "\n",
    "# Load catchment block‐group \n",
    "assignment_df = pd.read_sql(\n",
    "    'SELECT \"UNIQUESCHOOLID\", \"GEOID\", \"distance\" FROM \"allhsgrades24\".tbl_cbg_finalassignment',\n",
    "    engine\n",
    ")\n",
    "assignment_df.columns = assignment_df.columns.str.lower()\n",
    "\n",
    "# Load ACS block‐group data\n",
    "census_df = pd.read_sql('SELECT * FROM census.acs2023_combined', engine)\n",
    "census_df.columns = census_df.columns.str.lower()\n",
    "\n",
    "# Join catchment areas to ACS on GEOID\n",
    "df_cbg = assignment_df.merge(census_df, on=\"geoid\", how=\"inner\")\n",
    "\n",
    "# Compute weighted‐average education/access metrics\n",
    "waea_cols = [\n",
    "    \"edu_less_than_hs\",\n",
    "    \"edu_hs_or_more\",\n",
    "    \"without_internet_subscription\",\n",
    "    \"households_no_computer\",\n",
    "    \"edu_population_25plus\",\n",
    "    \"total_households_computer_internet\"\n",
    "]\n",
    "waea = (\n",
    "    df_cbg\n",
    "    .groupby(\"uniqueschoolid\")\n",
    "    .apply(lambda g: {\n",
    "        col: g[col].sum() / g[\"edu_population_25plus\"].sum()\n",
    "        for col in waea_cols\n",
    "    })\n",
    "    .apply(pd.Series)\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to percentages\n",
    "waea[waea_cols] *= 100\n",
    "waea.rename(\n",
    "    columns={col: f\"weighted_avg_{col}\" for col in waea_cols},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Compute population‐weighted average per-capita income\n",
    "df_income = df_cbg.dropna(subset=[\"total_population\", \"percapita_income_total\"])\n",
    "income = (\n",
    "    df_income\n",
    "    .groupby(\"uniqueschoolid\")\n",
    "    .apply(lambda g: (\n",
    "        (g[\"total_population\"] * g[\"percapita_income_total\"]).sum()\n",
    "        / g[\"total_population\"].sum()\n",
    "    ))\n",
    "    .reset_index(name=\"total_pop_weighted_avg_income\")\n",
    ")\n",
    "\n",
    "# Compute harmonic mean distances\n",
    "def harmonic_weighted_distance(df, distance_col, pop_cols):\n",
    "    rows = []\n",
    "    for uid, grp in df.groupby(\"uniqueschoolid\"):\n",
    "        row = {\"uniqueschoolid\": uid}\n",
    "        for col in pop_cols:\n",
    "            num = grp[col].sum()\n",
    "            denom = (grp[col] / grp[distance_col]).sum()\n",
    "            row[f\"{col}_population_avg_distance\"] = num / denom if denom != 0 else None\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "pop_cols = [\n",
    "    \"white_alone_non_hispanic\",\n",
    "    \"black_alone_non_hispanic\",\n",
    "    \"asian_alone_non_hispanic\",\n",
    "    \"hispanic_or_latino\"\n",
    "]\n",
    "distance = harmonic_weighted_distance(df_cbg, \"distance\", pop_cols)\n",
    "\n",
    "# Merge all census‐derived metrics\n",
    "metrics = waea.merge(income, on=\"uniqueschoolid\", how=\"outer\")\n",
    "metrics = metrics.merge(distance, on=\"uniqueschoolid\", how=\"outer\")\n",
    "\n",
    "# Final join: school data + RI + metrics\n",
    "df = school_metrics.merge(metrics, on=\"uniqueschoolid\", how=\"left\")\n",
    "\n",
    "# Prepare for plotting\n",
    "soft_palette = {\"Underrepresented\": \"#FDBF6F\", \"Overrepresented\": \"#A6CEE3\"}\n",
    "\n",
    "variables = {\n",
    "    \"Income\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",   \"total_pop_weighted_avg_income\"),\n",
    "            \"Black\":    (\"ri_black\",   \"total_pop_weighted_avg_income\"),\n",
    "            \"Asian\":    (\"ri_asian\",   \"total_pop_weighted_avg_income\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"total_pop_weighted_avg_income\")\n",
    "        },\n",
    "        \"xlabel\":      \"Population-Weighted Avg. Per Capita Income in USD (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and Income by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and Income by Locale\"\n",
    "    },\n",
    "    \"Harmonic Mean Distance\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",  \"white_alone_non_hispanic_population_avg_distance\"),\n",
    "            \"Black\":    (\"ri_black\",  \"black_alone_non_hispanic_population_avg_distance\"),\n",
    "            \"Asian\":    (\"ri_asian\",  \"asian_alone_non_hispanic_population_avg_distance\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"hispanic_or_latino_population_avg_distance\")\n",
    "        },\n",
    "        \"xlabel\":      \"Harmonic Mean of Population-Distance in meters (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and Distance by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and Distance by Locale\"\n",
    "    },\n",
    "    \"No Computer\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",  \"weighted_avg_households_no_computer\"),\n",
    "            \"Black\":    (\"ri_black\",  \"weighted_avg_households_no_computer\"),\n",
    "            \"Asian\":    (\"ri_asian\",  \"weighted_avg_households_no_computer\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"weighted_avg_households_no_computer\")\n",
    "        },\n",
    "        \"xlabel\":      \"Weighted % of Households Without Computer (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and No Computer Access by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and No Computer Access by Locale\"\n",
    "    },\n",
    "    \"Comp But No Internet\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",  \"weighted_avg_without_internet_subscription\"),\n",
    "            \"Black\":    (\"ri_black\",  \"weighted_avg_without_internet_subscription\"),\n",
    "            \"Asian\":    (\"ri_asian\",  \"weighted_avg_without_internet_subscription\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"weighted_avg_without_internet_subscription\")\n",
    "        },\n",
    "        \"xlabel\":      \"Weighted % Without Internet Subscription (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and No Internet Access by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and No Internet Access by Locale\"\n",
    "    },\n",
    "    \"Less than High School\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",  \"weighted_avg_edu_less_than_hs\"),\n",
    "            \"Black\":    (\"ri_black\",  \"weighted_avg_edu_less_than_hs\"),\n",
    "            \"Asian\":    (\"ri_asian\",  \"weighted_avg_edu_less_than_hs\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"weighted_avg_edu_less_than_hs\")\n",
    "        },\n",
    "        \"xlabel\":      \"Weighted % with <HS Degree (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and <HS Education by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and <HS Education by Locale\"\n",
    "    },\n",
    "    \"Completed HS and Higher\": {\n",
    "        \"columns\": {\n",
    "            \"White\":    (\"ri_white\",  \"weighted_avg_edu_hs_or_more\"),\n",
    "            \"Black\":    (\"ri_black\",  \"weighted_avg_edu_hs_or_more\"),\n",
    "            \"Asian\":    (\"ri_asian\",  \"weighted_avg_edu_hs_or_more\"),\n",
    "            \"Hispanic\": (\"ri_hispanic\",\"weighted_avg_edu_hs_or_more\")\n",
    "        },\n",
    "        \"xlabel\":      \"Weighted % Completing HS or More (with quartiles)\",\n",
    "        \"title_race\":  \"Distribution of $RI_X$ and HS Completion by Race\",\n",
    "        \"title_locale\":\"Distribution of $RI_X$ and HS Completion by Locale\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def draw_consistent_grid_lines(ax, y_values, x_max):\n",
    "    for y in y_values:\n",
    "        for line in ax.lines[:]:\n",
    "            if len(line.get_ydata()) == 2 and abs(line.get_ydata()[0] - y) < 0.01:\n",
    "                line.remove()\n",
    "        ln = ax.axhline(y=y, xmin=0, xmax=1, linestyle='--', linewidth=1, alpha=1.0, zorder=0)\n",
    "        ln.set_clip_on(False)\n",
    "        ln.set_dashes([5, 2])\n",
    "\n",
    "for var_name, meta in variables.items():\n",
    "    cleaned = []\n",
    "    for race, (ri_col, val_col) in meta[\"columns\"].items():\n",
    "        temp_all = df[[ri_col, val_col, \"locale\"]].dropna().copy()\n",
    "        temp_all[\"race\"] = race\n",
    "        temp_all[\"representation\"] = \"Parity\"\n",
    "        temp_all.loc[temp_all[ri_col] > 0.05, \"representation\"] = \"Overrepresented\"\n",
    "        temp_all.loc[temp_all[ri_col] < -0.05, \"representation\"] = \"Underrepresented\"\n",
    "        tmp = temp_all[temp_all[\"representation\"] != \"Parity\"].copy()\n",
    "        tmp.rename(columns={val_col: var_name.lower()}, inplace=True)\n",
    "        cleaned.append(tmp)\n",
    "\n",
    "    df_violin = pd.concat(cleaned, ignore_index=True)\n",
    "\n",
    "    # Race‐wise violin\n",
    "    fig, ax_race = plt.subplots(figsize=(12, 7), dpi=300)\n",
    "    sns.violinplot(\n",
    "        data=df_violin,\n",
    "        x=var_name.lower(),\n",
    "        y=\"race\",\n",
    "        hue=\"representation\",\n",
    "        split=True,\n",
    "        hue_order=[\"Overrepresented\", \"Underrepresented\"],\n",
    "        palette=soft_palette,\n",
    "        cut=0, bw=0.2, scale=\"width\", gap=0.2, inner=\"quart\",\n",
    "        ax=ax_race\n",
    "    )\n",
    "    ax_race.set_xlim(left=0)\n",
    "    ax_race.set_title(meta[\"title_race\"], fontsize=14)\n",
    "    ax_race.set_xlabel(meta[\"xlabel\"], fontsize=12)\n",
    "    ax_race.set_ylabel(\"Race\", fontsize=12, labelpad=40)\n",
    "    ax_race.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    races = df_violin[\"race\"].unique()\n",
    "    yticks = range(len(races))\n",
    "    ax_race.set_yticks(yticks)\n",
    "    ax_race.set_yticklabels(races, fontsize=9)\n",
    "    ax_race.text(-0.07, 0.97, \"Count\", transform=ax_race.transAxes,\n",
    "                 fontsize=8, ha='right', va='bottom', fontweight='bold')\n",
    "    draw_consistent_grid_lines(ax_race, yticks, ax_race.get_xlim()[1]*0.95)\n",
    "\n",
    "    for i, race in enumerate(races):\n",
    "        race_all = df[[meta[\"columns\"][race][0], \"locale\"]].dropna().copy()\n",
    "        race_all[\"representation\"] = \"Parity\"\n",
    "        race_all.loc[race_all[meta[\"columns\"][race][0]] > 0.05, \"representation\"] = \"Overrepresented\"\n",
    "        race_all.loc[race_all[meta[\"columns\"][race][0]] < -0.05, \"representation\"] = \"Underrepresented\"\n",
    "\n",
    "        over = (race_all[\"representation\"] == \"Overrepresented\").sum()\n",
    "        par  = (race_all[\"representation\"] == \"Parity\").sum()\n",
    "        under= (race_all[\"representation\"] == \"Underrepresented\").sum()\n",
    "\n",
    "        plt.text(-0.07, i+0.15, f\"↓{under}\", transform=ax_race.get_yaxis_transform(),\n",
    "                 fontsize=9, ha='right', va='center')\n",
    "        plt.text(-0.07, i,        f\"={par}\",   transform=ax_race.get_yaxis_transform(),\n",
    "                 fontsize=9, ha='right', va='center')\n",
    "        plt.text(-0.07, i-0.15,   f\"↑{over}\",  transform=ax_race.get_yaxis_transform(),\n",
    "                 fontsize=9, ha='right', va='center')\n",
    "\n",
    "    ax_race.legend_.remove()\n",
    "    plt.legend(\n",
    "        handles=[\n",
    "            Patch(facecolor=soft_palette[\"Overrepresented\"], label=\"Overrepresented (>+0.05)\"),\n",
    "            Patch(facecolor=soft_palette[\"Underrepresented\"], label=\"Underrepresented (<-0.05)\")\n",
    "        ],\n",
    "        title=\"$RI_X$\",\n",
    "        loc=\"upper right\",\n",
    "        fontsize=8,\n",
    "        title_fontsize=9,\n",
    "        borderpad=0.3,\n",
    "        labelspacing=0.3\n",
    "    )\n",
    "    ax_race.text(0.85, 0.78,\n",
    "                 \"Count symbols:\\n↑ : Overrepresented\\n= : Parity\\n↓ : Underrepresented\",\n",
    "                 transform=ax_race.transAxes,\n",
    "                 fontsize=8, ha='left', va='top',\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8,\n",
    "                           edgecolor='gray', linewidth=0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.savefig(f'output_394/violin_race_{var_name.lower().replace(\" \", \"_\")}_394.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Locale‐wise violin\n",
    "    fig, ax_locale = plt.subplots(figsize=(12, 7), dpi=300)\n",
    "    sns.violinplot(\n",
    "        data=df_violin,\n",
    "        x=var_name.lower(),\n",
    "        y=\"locale\",\n",
    "        hue=\"representation\",\n",
    "        split=True,\n",
    "        hue_order=[\"Overrepresented\", \"Underrepresented\"],\n",
    "        palette=soft_palette,\n",
    "        cut=0, bw=0.2, scale=\"width\", gap=0.2, inner=\"quart\",\n",
    "        ax=ax_locale\n",
    "    )\n",
    "    ax_locale.set_xlim(left=0)\n",
    "    ax_locale.set_title(meta[\"title_locale\"], fontsize=14)\n",
    "    ax_locale.set_xlabel(meta[\"xlabel\"], fontsize=12)\n",
    "    ax_locale.set_ylabel(\"Locale\", fontsize=12, labelpad=40)\n",
    "    ax_locale.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    locales = df_violin[\"locale\"].unique()\n",
    "    yticks = range(len(locales))\n",
    "    ax_locale.set_yticks(yticks)\n",
    "    ax_locale.set_yticklabels(locales, fontsize=9)\n",
    "    ax_locale.text(-0.07, 0.97, \"Count\", transform=ax_locale.transAxes,\n",
    "                   fontsize=8, ha='right', va='bottom')\n",
    "    draw_consistent_grid_lines(ax_locale, yticks, ax_locale.get_xlim()[1]*0.95)\n",
    "\n",
    "    for i, loc in enumerate(locales):\n",
    "        counts = {\"Overrepresented\": 0, \"Parity\": 0, \"Underrepresented\": 0}\n",
    "        for race in variables[var_name][\"columns\"]:\n",
    "            sub = df[(df[\"locale\"] == loc) & (~df[f\"ri_{race.lower()}\"].isna())].copy()\n",
    "            sub[\"representation\"] = \"Parity\"\n",
    "            sub.loc[sub[f\"ri_{race.lower()}\"] > 0.05, \"representation\"] = \"Overrepresented\"\n",
    "            sub.loc[sub[f\"ri_{race.lower()}\"] < -0.05, \"representation\"] = \"Underrepresented\"\n",
    "            for rep in counts:\n",
    "                counts[rep] += (sub[\"representation\"] == rep).sum()\n",
    "\n",
    "        plt.text(-0.07, i+0.15, f\"↓{counts['Underrepresented']}\",\n",
    "                 transform=ax_locale.get_yaxis_transform(), fontsize=9, ha='right', va='center')\n",
    "        plt.text(-0.07, i,        f\"={counts['Parity']}\",\n",
    "                 transform=ax_locale.get_yaxis_transform(), fontsize=9, ha='right', va='center')\n",
    "        plt.text(-0.07, i-0.15,   f\"↑{counts['Overrepresented']}\",\n",
    "                 transform=ax_locale.get_yaxis_transform(), fontsize=9, ha='right', va='center')\n",
    "\n",
    "    ax_locale.legend_.remove()\n",
    "    plt.legend(\n",
    "        handles=[\n",
    "            Patch(facecolor=soft_palette[\"Overrepresented\"], label=\"Overrepresented (>+0.05)\"),\n",
    "            Patch(facecolor=soft_palette[\"Underrepresented\"], label=\"Underrepresented (<-0.05)\")\n",
    "        ],\n",
    "        title=\"$RI_X$\",\n",
    "        loc=\"upper right\",\n",
    "        fontsize=8,\n",
    "        title_fontsize=9,\n",
    "        borderpad=0.3,\n",
    "        labelspacing=0.3\n",
    "    )\n",
    "    ax_locale.text(0.85, 0.78,\n",
    "                   \"Count symbols:\\n↑ : Overrepresented\\n= : Parity\\n↓ : Underrepresented\",\n",
    "                   transform=ax_locale.transAxes,\n",
    "                   fontsize=8, ha='left', va='top',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8,\n",
    "                             edgecolor='gray', linewidth=0.5))\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.savefig(f'output_394/violin_locale_{var_name.lower().replace(\" \", \"_\")}_394.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"All plots have been generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f5e28",
   "metadata": {},
   "source": [
    "#### Scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274b6aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/2710911043.py:53: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: {\n",
      "/var/folders/z1/89p5283s11d507yd60c1dqm40000gn/T/ipykernel_81205/2710911043.py:73: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"postgresql://cosea_user:CoSeaIndex@pgsql.dataconn.net:5432/cosea_db\"\n",
    ")\n",
    "\n",
    "# Load school data\n",
    "school_df = pd.read_sql(\n",
    "    'SELECT * FROM \"allhsgrades24\".tbl_approvedschools', engine)\n",
    "school_df.columns = school_df.columns.str.lower()\n",
    "\n",
    "# Load RI columns -- added ri_gap - make sure you run the SQL query to create this column\n",
    "ri_df = pd.read_sql(\n",
    "    'SELECT \"UNIQUESCHOOLID\", \"RI_White\", \"RI_Black\", \"RI_Asian\", \"RI_Hispanic\", \"ri_gap\" '\n",
    "    'FROM census.gadoe2024_389',\n",
    "    engine\n",
    ")\n",
    "ri_df.columns = ri_df.columns.str.lower()\n",
    "school_metrics = school_df.merge(ri_df, on=\"uniqueschoolid\", how=\"left\")\n",
    "\n",
    "# Load catchment block‐group\n",
    "assignment_df = pd.read_sql(\n",
    "    'SELECT \"UNIQUESCHOOLID\", \"GEOID\", \"distance\" FROM \"allhsgrades24\".tbl_cbg_finalassignment',\n",
    "    engine\n",
    ")\n",
    "assignment_df.columns = assignment_df.columns.str.lower()\n",
    "\n",
    "# Load ACS block‐group data\n",
    "census_df = pd.read_sql('SELECT * FROM census.acs2023_combined', engine)\n",
    "census_df.columns = census_df.columns.str.lower()\n",
    "\n",
    "# Join catchment areas to ACS on GEOID\n",
    "df_cbg = assignment_df.merge(census_df, on=\"geoid\", how=\"inner\")\n",
    "\n",
    "# Compute weighted‐average education/access metrics\n",
    "waea_cols = [\n",
    "    \"edu_less_than_hs\",\n",
    "    \"edu_hs_or_more\",\n",
    "    \"without_internet_subscription\",\n",
    "    \"households_no_computer\",\n",
    "    \"edu_population_25plus\",\n",
    "    \"total_households_computer_internet\"\n",
    "]\n",
    "waea = (\n",
    "    df_cbg\n",
    "    .groupby(\"uniqueschoolid\")\n",
    "    .apply(lambda g: {\n",
    "        col: g[col].sum() / g[\"total_households_computer_internet\"].sum()\n",
    "        for col in waea_cols\n",
    "    })\n",
    "    .apply(pd.Series)\n",
    "    .reset_index()\n",
    ")\n",
    "# convert to percentages\n",
    "waea[waea_cols] *= 100\n",
    "waea.rename(\n",
    "    columns={col: f\"weighted_avg_{col}\" for col in waea_cols},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Compute population‐weighted average per-capita income\n",
    "df_income = df_cbg.dropna(\n",
    "    subset=[\"total_population\", \"percapita_income_total\"])\n",
    "income = (\n",
    "    df_income\n",
    "    .groupby(\"uniqueschoolid\")\n",
    "    .apply(lambda g: (\n",
    "        (g[\"total_population\"] * g[\"percapita_income_total\"]).sum()\n",
    "        / g[\"total_population\"].sum()\n",
    "    ))\n",
    "    .reset_index(name=\"total_pop_weighted_avg_income\")\n",
    ")\n",
    "\n",
    "# Compute harmonic mean distances\n",
    "\n",
    "\n",
    "def harmonic_weighted_distance(df, distance_col, pop_cols):\n",
    "    rows = []\n",
    "    for uid, grp in df.groupby(\"uniqueschoolid\"):\n",
    "        row = {\"uniqueschoolid\": uid}\n",
    "        for col in pop_cols:\n",
    "            num = grp[col].sum()\n",
    "            denom = (grp[col] / grp[distance_col]).sum()\n",
    "            row[f\"{col}_population_avg_distance\"] = num / \\\n",
    "                denom if denom != 0 else None\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "pop_cols = [\n",
    "    \"white_alone_non_hispanic\",\n",
    "    \"black_alone_non_hispanic\",\n",
    "    \"asian_alone_non_hispanic\",\n",
    "    \"hispanic_or_latino\",\n",
    "    \"total_population\"  # added this line to include total population\n",
    "]\n",
    "distance = harmonic_weighted_distance(df_cbg, \"distance\", pop_cols)\n",
    "\n",
    "# Merge all census‐derived metrics\n",
    "metrics = waea.merge(income, on=\"uniqueschoolid\", how=\"outer\")\n",
    "metrics = metrics.merge(distance, on=\"uniqueschoolid\", how=\"outer\")\n",
    "\n",
    "# Final join: school data + RI + metrics\n",
    "df = school_metrics.merge(metrics, on=\"uniqueschoolid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ff76e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame columns: ['fiscal_year', 'fiscal_count', 'system_id', 'system_name', 'school_id', 'school_name', 'grade_range', 'fac_schtype', 'total student count', 'ethnicity: hispanic', 'race: american indian', 'race: asian', 'race: black', 'race: pacific islander', 'race: white', 'race: two or more races', 'female', 'male', 'uniqueschoolid', 'school address', 'school city', 'state', 'lat', 'lon', 'schoolgeom', 'locale code', 'locale', 'buffer_distance', 'ri_white', 'ri_black', 'ri_asian', 'ri_hispanic', 'ri_gap', 'weighted_avg_edu_less_than_hs', 'weighted_avg_edu_hs_or_more', 'weighted_avg_without_internet_subscription', 'weighted_avg_households_no_computer', 'weighted_avg_edu_population_25plus', 'weighted_avg_total_households_computer_internet', 'total_pop_weighted_avg_income', 'white_alone_non_hispanic_population_avg_distance', 'black_alone_non_hispanic_population_avg_distance', 'asian_alone_non_hispanic_population_avg_distance', 'hispanic_or_latino_population_avg_distance', 'total_population_population_avg_distance']\n",
      "weighted_avg_edu_less_than_hs: 324 rows\n",
      "weighted_avg_edu_hs_or_more: 324 rows\n",
      "weighted_avg_without_internet_subscription: 324 rows\n",
      "weighted_avg_households_no_computer: 324 rows\n",
      "total_pop_weighted_avg_income: 324 rows\n",
      "total_population_population_avg_distance: 324 rows\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Check and print columns\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "if 'ri_gap' not in df.columns:\n",
    "    raise ValueError(\n",
    "        \"The 'ri_gap' column is missing from the DataFrame. Please ensure it is computed before running this script.\")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"output_394/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Optional: rename columns for axis labels\n",
    "column_rename_map = {\n",
    "    'weighted_avg_edu_less_than_hs': 'Less than High School (%)',\n",
    "    'weighted_avg_edu_hs_or_more': 'High School or More (%)',\n",
    "    'weighted_avg_without_internet_subscription': 'No Internet (%)',\n",
    "    'weighted_avg_households_no_computer': 'No Computer in Household (%)',\n",
    "    'total_pop_weighted_avg_income': 'Weighted Income ($)',\n",
    "    'total_population_population_avg_distance': 'Weighted Distance (meters)'\n",
    "}\n",
    "\n",
    "# List of predictor variables\n",
    "predictor_vars = list(column_rename_map.keys())\n",
    "\n",
    "# Desired order of locales\n",
    "locale_order = ['City', 'Suburb', 'Town', 'Rural']\n",
    "\n",
    "# Plot settings\n",
    "sns.set(style=\"whitegrid\", context='talk')\n",
    "\n",
    "for var in predictor_vars:\n",
    "    subset = df[[var, 'ri_gap', 'locale']].dropna()\n",
    "    print(f\"{var}: {subset.shape[0]} rows\")\n",
    "\n",
    "    g = sns.FacetGrid(\n",
    "        subset,\n",
    "        col='locale',\n",
    "        col_order=locale_order,\n",
    "        col_wrap=2,\n",
    "        height=4.5,\n",
    "        aspect=1.2,\n",
    "        sharex=True,\n",
    "        sharey=True\n",
    "    )\n",
    "\n",
    "    g.map_dataframe(\n",
    "        sns.regplot,\n",
    "        x=var,\n",
    "        y='ri_gap',\n",
    "        scatter_kws={'alpha': 0.6, 's': 30, 'color': '#FDBF6F'},\n",
    "        line_kws={'color': '#A6CEE3'},\n",
    "        ci=95,\n",
    "        truncate=True\n",
    "    )\n",
    "\n",
    "    x_label = column_rename_map.get(var, var.replace('_', ' ').title())\n",
    "    g.set_axis_labels(x_label, \"Representation Gap\")\n",
    "    g.set_titles(col_template=\"{col_name}\")\n",
    "    g.set(ylim=(0, 1))\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        ax.tick_params(labelsize=10)\n",
    "\n",
    "    g.fig.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(x_label + \" vs Representation Gap\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Construct filename\n",
    "    safe_var_name = var.replace(' ', '_')\n",
    "    filename = f\"scatterplots_{safe_var_name}_394.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    g.savefig(filepath, dpi=300)\n",
    "    plt.close(g.fig)  # Avoid overlap in next figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
