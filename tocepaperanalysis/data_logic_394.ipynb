{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fade6a1",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "Load required libraries, define approved courses, and query data from the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0cfd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved Schools: 394\n",
      "FTE: 2322\n",
      "Computer Science Courses: 5820\n",
      "Computer Science Teachers: 7440\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create database connection\n",
    "engine = create_engine(\"postgresql://cosea_user:CoSeaIndex@pgsql.dataconn.net:5432/cosea_db\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# list of approved computer science course titles\n",
    "approved_courses = [\n",
    "    \"advanced placement, computer science a\",\n",
    "    \"advanced placement computer science principles\",\n",
    "    \"ib computer science, year one\",\n",
    "    \"ib computer science, year two\",\n",
    "    \"computer science principles\",\n",
    "    \"programming, games, apps and society\",\n",
    "    \"web development\",\n",
    "    \"embedded computing\",\n",
    "    \"game design: animation and simulation\",\n",
    "    \"introduction to cybersecurity\",\n",
    "    \"advanced cybersecurity\",\n",
    "    \"coding for fintech\",\n",
    "    \"introduction to python\"\n",
    "]\n",
    "\n",
    "# expanded list including additional courses for _2 logic\n",
    "expanded_courses = approved_courses + [\n",
    "    \"introduction to software technology\",\n",
    "    \"introduction to digital technology\",\n",
    "    \"introduction to hardware technology\"\n",
    "]\n",
    "\n",
    "# load tables from PostgreSQL\n",
    "approved = pd.read_sql('SELECT * FROM \"allhsgrades24\".\"tbl_approvedschools\"', engine)\n",
    "fte = pd.read_sql('SELECT * FROM \"allhsgrades24\".\"fte2024-1_enroll-demog_sch\"', engine)\n",
    "sc_full = pd.read_sql('SELECT * FROM \"allhsgrades24\".\"sc2024_l_comp_sci_crs_enroll_demog_sch\"', engine)\n",
    "sc = sc_full.copy()\n",
    "cs_teacher = pd.read_sql('SELECT * FROM \"allhsgrades24\".\"sc2024_l_comp_sci_crs_tch_roster_sch\"', engine)\n",
    "\n",
    "# print counts of records in each table\n",
    "print(f\"Approved Schools: {len(approved)}\")\n",
    "print(f\"FTE: {len(fte)}\")\n",
    "print(f\"Computer Science Courses: {len(sc)}\")\n",
    "print(f\"Computer Science Teachers: {len(cs_teacher)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515d92a",
   "metadata": {},
   "source": [
    "## Data Formatting and Cleaning\n",
    "Standardize ID formats, clean certificate IDs, and normalize course titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9564c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize IDs and generate unique school ID\n",
    "for df in [approved, fte, sc, cs_teacher, sc_full]:\n",
    "    df[\"SYSTEM_ID\"] = df[\"SYSTEM_ID\"].astype(str).str.zfill(4)\n",
    "    df[\"SCHOOL_ID\"] = df[\"SCHOOL_ID\"].astype(str).str.zfill(4)\n",
    "    df[\"UNIQUESCHOOLID\"] = df[\"SYSTEM_ID\"] + df[\"SCHOOL_ID\"]\n",
    "\n",
    "# clean certificate IDs\n",
    "cs_teacher[\"CERTIFICATE_ID\"] = cs_teacher[\"CERTIFICATE_ID\"].replace([\"n/a\", \"N/A\", \".\", \"\"], pd.NA)\n",
    "cs_teacher[\"CERTIFICATE_ID\"] = pd.to_numeric(cs_teacher[\"CERTIFICATE_ID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# count certified teachers per school\n",
    "certified = cs_teacher.groupby(\"UNIQUESCHOOLID\")[\"CERTIFICATE_ID\"].nunique().reset_index()\n",
    "certified.rename(columns={\"CERTIFICATE_ID\": \"Certified_Teachers\"}, inplace=True)\n",
    "\n",
    "# normalize course titles to lowercase\n",
    "sc[\"COURSE_TITLE\"] = sc[\"COURSE_TITLE\"].astype(str).str.lower()\n",
    "sc_full[\"COURSE_TITLE\"] = sc_full[\"COURSE_TITLE\"].astype(str).str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978742c6",
   "metadata": {},
   "source": [
    "## Aggregate Enrollment and Demographics\n",
    "Summarize CS course taker data and clean total enrollment data from FTE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5b61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate CS enrollment by school for approved courses\n",
    "sc_for_enrollment = sc[sc[\"COURSE_TITLE\"].isin(expanded_courses)]\n",
    "sc_agg = sc_for_enrollment.groupby(\"UNIQUESCHOOLID\", as_index=False).agg({\n",
    "    \"COURSE_TAKER_CT\": \"sum\",\n",
    "    \"Race: Asian\": \"sum\",\n",
    "    \"Race: Black\": \"sum\",\n",
    "    \"Race: White\": \"sum\",\n",
    "    \"Ethnicity: Hispanic\": \"sum\",\n",
    "    \"Female\": \"sum\",\n",
    "    \"Male\": \"sum\"\n",
    "}).rename(columns={\n",
    "    \"COURSE_TAKER_CT\": \"CS_Enrollment\",\n",
    "    \"Race: Asian\": \"CS_Asian\",\n",
    "    \"Race: Black\": \"CS_Black\",\n",
    "    \"Race: White\": \"CS_White\",\n",
    "    \"Ethnicity: Hispanic\": \"CS_Hispanic\",\n",
    "    \"Female\": \"CS_Female\",\n",
    "    \"Male\": \"CS_Male\"\n",
    "})\n",
    "\n",
    "# clean FTE values and demographics\n",
    "fte[\"Total_Enrollment\"] = pd.to_numeric(fte[\"Total Student Count\"], errors=\"coerce\")\n",
    "for col in [\"Race: Asian\", \"Race: Black\", \"Race: White\", \"Ethnicity: Hispanic\", \"Female\", \"Male\"]:\n",
    "    fte[col] = pd.to_numeric(fte[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "fte_clean = fte[[\n",
    "    \"UNIQUESCHOOLID\", \"Total_Enrollment\",\n",
    "    \"Race: Asian\", \"Race: Black\", \"Race: White\", \"Ethnicity: Hispanic\",\n",
    "    \"Female\", \"Male\"\n",
    "]].rename(columns={\n",
    "    \"Race: Asian\": \"Total_Asian\",\n",
    "    \"Race: Black\": \"Total_Black\",\n",
    "    \"Race: White\": \"Total_White\",\n",
    "    \"Ethnicity: Hispanic\": \"Total_Hispanic\",\n",
    "    \"Female\": \"Total_Female\",\n",
    "    \"Male\": \"Total_Male\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1865e296",
   "metadata": {},
   "source": [
    "## Merge All Data and Compute Representation Index (RI)\n",
    "Join all datasets and compute the RI metric for each race/gender group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6135956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all sources\n",
    "merged = pd.merge(approved, fte_clean, on=\"UNIQUESCHOOLID\", how=\"left\")\n",
    "merged = pd.merge(merged, sc_agg, on=\"UNIQUESCHOOLID\", how=\"left\")\n",
    "merged = pd.merge(merged, certified, on=\"UNIQUESCHOOLID\", how=\"left\")\n",
    "merged = merged[merged[\"Total_Enrollment\"] > 0]\n",
    "\n",
    "# fill NA with zeros for CS fields\n",
    "merged[\"CS_Enrollment\"] = merged[\"CS_Enrollment\"].fillna(0)\n",
    "for col in [\"CS_Asian\", \"CS_Black\", \"CS_White\", \"CS_Hispanic\", \"CS_Female\", \"CS_Male\"]:\n",
    "    merged[col] = merged[col].fillna(0)\n",
    "\n",
    "# compute Representation Index (RI)\n",
    "race_pairs = {\n",
    "    \"Asian\": (\"CS_Asian\", \"Total_Asian\"),\n",
    "    \"Black\": (\"CS_Black\", \"Total_Black\"),\n",
    "    \"Hispanic\": (\"CS_Hispanic\", \"Total_Hispanic\"),\n",
    "    \"White\": (\"CS_White\", \"Total_White\"),\n",
    "    \"Female\": (\"CS_Female\", \"Total_Female\")\n",
    "}\n",
    "\n",
    "for race, (cs_col, total_col) in race_pairs.items():\n",
    "    cs_share = np.where(merged[\"CS_Enrollment\"] == 0, 0, merged[cs_col] / merged[\"CS_Enrollment\"])\n",
    "    school_share = np.where(merged[\"CS_Enrollment\"] == 0, 0, merged[total_col] / merged[\"Total_Enrollment\"])\n",
    "    merged[f\"RI_{race}\"] = cs_share - school_share\n",
    "\n",
    "# add schools from approved that were missing\n",
    "missing_ids = set(approved[\"UNIQUESCHOOLID\"]) - set(merged[\"UNIQUESCHOOLID\"])\n",
    "if missing_ids:\n",
    "    print(f\"appending {len(missing_ids)} schools missing from merged\")\n",
    "    extras = approved[approved[\"UNIQUESCHOOLID\"].isin(missing_ids)].copy()\n",
    "    extras[\"Total_Enrollment\"] = 0\n",
    "    extras[\"CS_Enrollment\"] = 0\n",
    "    for col in [\"CS_Asian\", \"CS_Black\", \"CS_White\", \"CS_Hispanic\", \"CS_Female\", \"CS_Male\",\n",
    "                \"Total_Asian\", \"Total_Black\", \"Total_White\", \"Total_Hispanic\", \"Total_Female\", \"Total_Male\",\n",
    "                \"Certified_Teachers\"]:\n",
    "        extras[col] = 0\n",
    "    for race in [\"Asian\", \"Black\", \"Hispanic\", \"White\", \"Female\"]:\n",
    "        extras[f\"RI_{race}\"] = np.nan\n",
    "    merged = pd.concat([merged, extras], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b1993",
   "metadata": {},
   "source": [
    "## Course-Level Logic (2-Digit)\n",
    "Build course-level logic flags based on approval and certification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a54ceab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated census.course_logic_2024\n"
     ]
    }
   ],
   "source": [
    "cs_teacher[\"COURSE_TITLE\"] = cs_teacher[\"COURSE_TITLE\"].astype(str).str.lower()\n",
    "cs_teacher[\"TEACHER_LAST_NAME\"] = cs_teacher[\"TEACHER_LAST_NAME\"].astype(str).str.lower()\n",
    "virtual_teachers = [\"software-based instruction\", \"gavs virtual teacher\", \"virtual school (non-gavs)\"]\n",
    "virtual_labels = [v.lower() for v in virtual_teachers]\n",
    "cs_teacher[\"is_virtual\"] = (\n",
    "    cs_teacher[\"TEACHER_LAST_NAME\"].isin(virtual_labels) |\n",
    "    cs_teacher[\"TEACHER_LAST_NAME\"].str.contains(\"de:\", na=False)\n",
    ")\n",
    "\n",
    "\n",
    "course_merge = pd.merge(\n",
    "    sc_full[[\"UNIQUESCHOOLID\", \"COURSE_NUMBER\", \"COURSE_TITLE\"]],\n",
    "    cs_teacher[[\"UNIQUESCHOOLID\", \"COURSE_NUMBER\", \"COURSE_TITLE\", \"CERTIFICATE_ID\", \"TEACHER_LAST_NAME\", \"is_virtual\"]],\n",
    "    on=[\"UNIQUESCHOOLID\", \"COURSE_NUMBER\", \"COURSE_TITLE\"],\n",
    "    how=\"outer\"\n",
    ").drop_duplicates()\n",
    "\n",
    "course_merge[\"approved_flag\"] = course_merge[\"COURSE_TITLE\"].isin(approved_courses).astype(int)\n",
    "course_merge[\"CERTIFICATE_ID\"] = pd.to_numeric(course_merge[\"CERTIFICATE_ID\"], errors=\"coerce\")\n",
    "course_merge[\"certified_flag\"] = course_merge[\"CERTIFICATE_ID\"].notna().astype(int)\n",
    "course_merge[\"COURSE_LOGIC\"] = course_merge[\"approved_flag\"].astype(str) + course_merge[\"certified_flag\"].astype(str)\n",
    "\n",
    "course_output = course_merge[\n",
    "    [\"UNIQUESCHOOLID\", \"COURSE_NUMBER\", \"COURSE_TITLE\", \"approved_flag\", \"certified_flag\", \"COURSE_LOGIC\", \"CERTIFICATE_ID\", \"TEACHER_LAST_NAME\", \"is_virtual\"]\n",
    "]\n",
    "\n",
    "course_output.to_sql(\"course_logic_2024\", engine, schema=\"census\", if_exists=\"replace\", index=False)\n",
    "print(\"updated census.course_logic_2024\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40292a3",
   "metadata": {},
   "source": [
    "## School-Level Logic (3-Digit) and Final Export\n",
    "Compute in-person, virtual, and extra teacher flags. Save the final output to PostgreSQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50445c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGIC_CLASS\n",
      "000    42\n",
      "001    21\n",
      "010    18\n",
      "011    10\n",
      "100    74\n",
      "101    77\n",
      "110    69\n",
      "111    83\n",
      "Name: count, dtype: int64\n",
      "updated census.gadoe2024_389 with LOGIC_CLASS\n"
     ]
    }
   ],
   "source": [
    "school_courses = course_output.copy()\n",
    "\n",
    "# logic flags\n",
    "in_person_cs = school_courses[(school_courses[\"approved_flag\"] == 1) & (~school_courses[\"is_virtual\"])][\"UNIQUESCHOOLID\"].unique()\n",
    "virtual_cs = school_courses[(school_courses[\"approved_flag\"] == 1) & (school_courses[\"is_virtual\"])][\"UNIQUESCHOOLID\"].unique()\n",
    "school_courses[\"Valid Course\"] = school_courses[\"approved_flag\"] == 1\n",
    "\n",
    "def check_teacher_extra(group):\n",
    "    return int(not group[\"Valid Course\"].any())\n",
    "\n",
    "extra_teachers = school_courses.groupby([\"UNIQUESCHOOLID\", \"CERTIFICATE_ID\"], group_keys=False).apply(\n",
    "    check_teacher_extra, include_groups=False\n",
    ").reset_index(name=\"Extra_Flag\")\n",
    "extra_certified_ids = extra_teachers[extra_teachers[\"Extra_Flag\"] == 1][\"UNIQUESCHOOLID\"].unique()\n",
    "\n",
    "# assign logic flags\n",
    "merged[\"L1_in_person\"] = merged[\"UNIQUESCHOOLID\"].isin(in_person_cs).astype(int)\n",
    "merged[\"L2_virtual\"] = merged[\"UNIQUESCHOOLID\"].isin(virtual_cs).astype(int)\n",
    "merged[\"L3_extra\"] = merged[\"UNIQUESCHOOLID\"].isin(extra_certified_ids).astype(int)\n",
    "merged[\"LOGIC_CLASS\"] = merged[\"L1_in_person\"].astype(str) + merged[\"L2_virtual\"].astype(str) + merged[\"L3_extra\"].astype(str)\n",
    "merged.drop(columns=[\"L1_in_person\", \"L2_virtual\", \"L3_extra\"], inplace=True)\n",
    "\n",
    "print(merged[\"LOGIC_CLASS\"].value_counts().sort_index())\n",
    "\n",
    "# export\n",
    "gadoe_output = merged[\n",
    "    [\n",
    "        \"UNIQUESCHOOLID\",\n",
    "        \"CS_Enrollment\", \"CS_Asian\", \"CS_Black\", \"CS_White\", \"CS_Hispanic\", \"CS_Female\", \"CS_Male\",\n",
    "        \"Certified_Teachers\",\n",
    "        \"RI_Asian\", \"RI_Black\", \"RI_Hispanic\", \"RI_White\", \"RI_Female\",\n",
    "        \"LOGIC_CLASS\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "gadoe_output.to_sql(\"gadoe2024_389\", engine, schema=\"census\", if_exists=\"replace\", index=False)\n",
    "print(\"updated census.gadoe2024_389 with LOGIC_CLASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08b3b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated census.course_logic_2024_389 with both original and expanded Logic Class 2 columns (_2)\n",
      "LOGIC_CLASS_2\n",
      "000     40\n",
      "001      4\n",
      "010     20\n",
      "011      3\n",
      "100    110\n",
      "101     18\n",
      "110    170\n",
      "111     29\n",
      "Name: count, dtype: int64\n",
      "updated census.gadoe2024_389 with LOGIC_CLASS_2\n"
     ]
    }
   ],
   "source": [
    "# define expanded approved course list\n",
    "expanded_courses = approved_courses + [\n",
    "    \"introduction to software technology\",\n",
    "    \"introduction to digital technology\",\n",
    "    \"introduction to hardware technology\"\n",
    " ]\n",
    "\n",
    "# reassign flags with expanded course list\n",
    "course_merge[\"approved_flag_2\"] = course_merge[\"COURSE_TITLE\"].isin(expanded_courses).astype(int)\n",
    "course_merge[\"certified_flag_2\"] = course_merge[\"CERTIFICATE_ID\"].notna().astype(int)\n",
    "course_merge[\"COURSE_LOGIC_2\"] = course_merge[\"approved_flag_2\"].astype(str) + course_merge[\"certified_flag_2\"].astype(str)\n",
    "\n",
    "course_output_full = course_merge[[\n",
    "    \"UNIQUESCHOOLID\",\n",
    "    \"COURSE_NUMBER\",\n",
    "    \"COURSE_TITLE\",\n",
    "    \"approved_flag\",\n",
    "    \"certified_flag\",\n",
    "    \"COURSE_LOGIC\",\n",
    "    \"approved_flag_2\",\n",
    "    \"certified_flag_2\",\n",
    "    \"COURSE_LOGIC_2\",\n",
    "    \"CERTIFICATE_ID\",\n",
    "    \"TEACHER_LAST_NAME\",\n",
    "    \"is_virtual\"\n",
    " ]]\n",
    "\n",
    "course_output_full.to_sql(\"course_logic_2024_389\", engine, schema=\"census\", if_exists=\"replace\", index=False)\n",
    "print(\"updated census.course_logic_2024_389 with both original and expanded Logic Class 2 columns (_2)\")\n",
    "\n",
    "school_courses_2 = course_merge.copy()\n",
    "in_person_cs_2 = school_courses_2[\n",
    "    (school_courses_2[\"approved_flag_2\"] == 1) & (~school_courses_2[\"is_virtual\"])\n",
    "][\"UNIQUESCHOOLID\"].unique()\n",
    "\n",
    "virtual_cs_2 = school_courses_2[\n",
    "    (school_courses_2[\"approved_flag_2\"] == 1) & (school_courses_2[\"is_virtual\"])\n",
    "][\"UNIQUESCHOOLID\"].unique()\n",
    "\n",
    "school_courses_2[\"Valid Course 2\"] = school_courses_2[\"approved_flag_2\"] == 1\n",
    "\n",
    "def check_teacher_extra_2(group):\n",
    "    return int(not group[\"Valid Course 2\"].any())\n",
    "\n",
    "extra_teachers_2 = school_courses_2.groupby([\"UNIQUESCHOOLID\", \"CERTIFICATE_ID\"], group_keys=False).apply(\n",
    "    check_teacher_extra_2, include_groups=False\n",
    ").reset_index(name=\"Extra_Flag_2\")\n",
    "\n",
    "extra_certified_ids_2 = extra_teachers_2[extra_teachers_2[\"Extra_Flag_2\"] == 1][\"UNIQUESCHOOLID\"].unique()\n",
    "\n",
    "# assign logic class 2\n",
    "merged[\"L1_in_person_2\"] = merged[\"UNIQUESCHOOLID\"].isin(in_person_cs_2).astype(int)\n",
    "merged[\"L2_virtual_2\"] = merged[\"UNIQUESCHOOLID\"].isin(virtual_cs_2).astype(int)\n",
    "merged[\"L3_extra_2\"] = merged[\"UNIQUESCHOOLID\"].isin(extra_certified_ids_2).astype(int)\n",
    "merged[\"LOGIC_CLASS_2\"] = (\n",
    "    merged[\"L1_in_person_2\"].astype(str) +\n",
    "    merged[\"L2_virtual_2\"].astype(str) +\n",
    "    merged[\"L3_extra_2\"].astype(str)\n",
    ")\n",
    "\n",
    "# clean up temp columns\n",
    "merged.drop(columns=[\"L1_in_person_2\", \"L2_virtual_2\", \"L3_extra_2\"], inplace=True)\n",
    "\n",
    "# show distribution\n",
    "print(merged[\"LOGIC_CLASS_2\"].value_counts().sort_index())\n",
    "\n",
    "# safely update output table\n",
    "gadoe_output = gadoe_output.copy()\n",
    "gadoe_output[\"LOGIC_CLASS_2\"] = merged[\"LOGIC_CLASS_2\"].values\n",
    "gadoe_output.to_sql(\"gadoe2024_389\", engine, schema=\"census\", if_exists=\"replace\", index=False)\n",
    "print(\"updated census.gadoe2024_389 with LOGIC_CLASS_2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345ff79",
   "metadata": {},
   "source": [
    "## RI Tables based on Locale type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c8f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_69901\">\n",
       "  <caption>Asian</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_69901_level0_col0\" class=\"col_heading level0 col0\" >Locale Type</th>\n",
       "      <th id=\"T_69901_level0_col1\" class=\"col_heading level0 col1\" >Overrepresentation (School Count)</th>\n",
       "      <th id=\"T_69901_level0_col2\" class=\"col_heading level0 col2\" >Parity (School Count)</th>\n",
       "      <th id=\"T_69901_level0_col3\" class=\"col_heading level0 col3\" >Underrepresentation (School Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_69901_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_69901_row0_col0\" class=\"data row0 col0\" >City</td>\n",
       "      <td id=\"T_69901_row0_col1\" class=\"data row0 col1\" >6</td>\n",
       "      <td id=\"T_69901_row0_col2\" class=\"data row0 col2\" >55</td>\n",
       "      <td id=\"T_69901_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69901_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_69901_row1_col0\" class=\"data row1 col0\" >Rural</td>\n",
       "      <td id=\"T_69901_row1_col1\" class=\"data row1 col1\" >14</td>\n",
       "      <td id=\"T_69901_row1_col2\" class=\"data row1 col2\" >124</td>\n",
       "      <td id=\"T_69901_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69901_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_69901_row2_col0\" class=\"data row2 col0\" >Suburb</td>\n",
       "      <td id=\"T_69901_row2_col1\" class=\"data row2 col1\" >58</td>\n",
       "      <td id=\"T_69901_row2_col2\" class=\"data row2 col2\" >94</td>\n",
       "      <td id=\"T_69901_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69901_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_69901_row3_col0\" class=\"data row3 col0\" >Town</td>\n",
       "      <td id=\"T_69901_row3_col1\" class=\"data row3 col1\" >6</td>\n",
       "      <td id=\"T_69901_row3_col2\" class=\"data row3 col2\" >37</td>\n",
       "      <td id=\"T_69901_row3_col3\" class=\"data row3 col3\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_69901_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_69901_row4_col0\" class=\"data row4 col0\" >Total</td>\n",
       "      <td id=\"T_69901_row4_col1\" class=\"data row4 col1\" >84</td>\n",
       "      <td id=\"T_69901_row4_col2\" class=\"data row4 col2\" >310</td>\n",
       "      <td id=\"T_69901_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120860a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1cf97\">\n",
       "  <caption>Black</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1cf97_level0_col0\" class=\"col_heading level0 col0\" >Locale Type</th>\n",
       "      <th id=\"T_1cf97_level0_col1\" class=\"col_heading level0 col1\" >Overrepresentation (School Count)</th>\n",
       "      <th id=\"T_1cf97_level0_col2\" class=\"col_heading level0 col2\" >Parity (School Count)</th>\n",
       "      <th id=\"T_1cf97_level0_col3\" class=\"col_heading level0 col3\" >Underrepresentation (School Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1cf97_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1cf97_row0_col0\" class=\"data row0 col0\" >City</td>\n",
       "      <td id=\"T_1cf97_row0_col1\" class=\"data row0 col1\" >10</td>\n",
       "      <td id=\"T_1cf97_row0_col2\" class=\"data row0 col2\" >32</td>\n",
       "      <td id=\"T_1cf97_row0_col3\" class=\"data row0 col3\" >19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cf97_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1cf97_row1_col0\" class=\"data row1 col0\" >Rural</td>\n",
       "      <td id=\"T_1cf97_row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "      <td id=\"T_1cf97_row1_col2\" class=\"data row1 col2\" >101</td>\n",
       "      <td id=\"T_1cf97_row1_col3\" class=\"data row1 col3\" >27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cf97_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1cf97_row2_col0\" class=\"data row2 col0\" >Suburb</td>\n",
       "      <td id=\"T_1cf97_row2_col1\" class=\"data row2 col1\" >20</td>\n",
       "      <td id=\"T_1cf97_row2_col2\" class=\"data row2 col2\" >106</td>\n",
       "      <td id=\"T_1cf97_row2_col3\" class=\"data row2 col3\" >26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cf97_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1cf97_row3_col0\" class=\"data row3 col0\" >Town</td>\n",
       "      <td id=\"T_1cf97_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "      <td id=\"T_1cf97_row3_col2\" class=\"data row3 col2\" >26</td>\n",
       "      <td id=\"T_1cf97_row3_col3\" class=\"data row3 col3\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cf97_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1cf97_row4_col0\" class=\"data row4 col0\" >Total</td>\n",
       "      <td id=\"T_1cf97_row4_col1\" class=\"data row4 col1\" >43</td>\n",
       "      <td id=\"T_1cf97_row4_col2\" class=\"data row4 col2\" >265</td>\n",
       "      <td id=\"T_1cf97_row4_col3\" class=\"data row4 col3\" >86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120860a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_89ab3\">\n",
       "  <caption>Hispanic</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_89ab3_level0_col0\" class=\"col_heading level0 col0\" >Locale Type</th>\n",
       "      <th id=\"T_89ab3_level0_col1\" class=\"col_heading level0 col1\" >Overrepresentation (School Count)</th>\n",
       "      <th id=\"T_89ab3_level0_col2\" class=\"col_heading level0 col2\" >Parity (School Count)</th>\n",
       "      <th id=\"T_89ab3_level0_col3\" class=\"col_heading level0 col3\" >Underrepresentation (School Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_89ab3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_89ab3_row0_col0\" class=\"data row0 col0\" >City</td>\n",
       "      <td id=\"T_89ab3_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "      <td id=\"T_89ab3_row0_col2\" class=\"data row0 col2\" >46</td>\n",
       "      <td id=\"T_89ab3_row0_col3\" class=\"data row0 col3\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89ab3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_89ab3_row1_col0\" class=\"data row1 col0\" >Rural</td>\n",
       "      <td id=\"T_89ab3_row1_col1\" class=\"data row1 col1\" >19</td>\n",
       "      <td id=\"T_89ab3_row1_col2\" class=\"data row1 col2\" >93</td>\n",
       "      <td id=\"T_89ab3_row1_col3\" class=\"data row1 col3\" >26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89ab3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_89ab3_row2_col0\" class=\"data row2 col0\" >Suburb</td>\n",
       "      <td id=\"T_89ab3_row2_col1\" class=\"data row2 col1\" >7</td>\n",
       "      <td id=\"T_89ab3_row2_col2\" class=\"data row2 col2\" >93</td>\n",
       "      <td id=\"T_89ab3_row2_col3\" class=\"data row2 col3\" >52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89ab3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_89ab3_row3_col0\" class=\"data row3 col0\" >Town</td>\n",
       "      <td id=\"T_89ab3_row3_col1\" class=\"data row3 col1\" >2</td>\n",
       "      <td id=\"T_89ab3_row3_col2\" class=\"data row3 col2\" >39</td>\n",
       "      <td id=\"T_89ab3_row3_col3\" class=\"data row3 col3\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_89ab3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_89ab3_row4_col0\" class=\"data row4 col0\" >Total</td>\n",
       "      <td id=\"T_89ab3_row4_col1\" class=\"data row4 col1\" >31</td>\n",
       "      <td id=\"T_89ab3_row4_col2\" class=\"data row4 col2\" >271</td>\n",
       "      <td id=\"T_89ab3_row4_col3\" class=\"data row4 col3\" >92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120860a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_634f2\">\n",
       "  <caption>White</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_634f2_level0_col0\" class=\"col_heading level0 col0\" >Locale Type</th>\n",
       "      <th id=\"T_634f2_level0_col1\" class=\"col_heading level0 col1\" >Overrepresentation (School Count)</th>\n",
       "      <th id=\"T_634f2_level0_col2\" class=\"col_heading level0 col2\" >Parity (School Count)</th>\n",
       "      <th id=\"T_634f2_level0_col3\" class=\"col_heading level0 col3\" >Underrepresentation (School Count)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_634f2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_634f2_row0_col0\" class=\"data row0 col0\" >City</td>\n",
       "      <td id=\"T_634f2_row0_col1\" class=\"data row0 col1\" >13</td>\n",
       "      <td id=\"T_634f2_row0_col2\" class=\"data row0 col2\" >40</td>\n",
       "      <td id=\"T_634f2_row0_col3\" class=\"data row0 col3\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_634f2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_634f2_row1_col0\" class=\"data row1 col0\" >Rural</td>\n",
       "      <td id=\"T_634f2_row1_col1\" class=\"data row1 col1\" >29</td>\n",
       "      <td id=\"T_634f2_row1_col2\" class=\"data row1 col2\" >80</td>\n",
       "      <td id=\"T_634f2_row1_col3\" class=\"data row1 col3\" >29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_634f2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_634f2_row2_col0\" class=\"data row2 col0\" >Suburb</td>\n",
       "      <td id=\"T_634f2_row2_col1\" class=\"data row2 col1\" >15</td>\n",
       "      <td id=\"T_634f2_row2_col2\" class=\"data row2 col2\" >104</td>\n",
       "      <td id=\"T_634f2_row2_col3\" class=\"data row2 col3\" >33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_634f2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_634f2_row3_col0\" class=\"data row3 col0\" >Town</td>\n",
       "      <td id=\"T_634f2_row3_col1\" class=\"data row3 col1\" >10</td>\n",
       "      <td id=\"T_634f2_row3_col2\" class=\"data row3 col2\" >25</td>\n",
       "      <td id=\"T_634f2_row3_col3\" class=\"data row3 col3\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_634f2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_634f2_row4_col0\" class=\"data row4 col0\" >Total</td>\n",
       "      <td id=\"T_634f2_row4_col1\" class=\"data row4 col1\" >67</td>\n",
       "      <td id=\"T_634f2_row4_col2\" class=\"data row4 col2\" >249</td>\n",
       "      <td id=\"T_634f2_row4_col3\" class=\"data row4 col3\" >78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x120860a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load gadoe data and approvedschools with Locale\n",
    "gadoe = pd.read_sql('SELECT * FROM \"census\".\"gadoe2024_389\"', engine)\n",
    "approved = pd.read_sql('SELECT \"UNIQUESCHOOLID\", \"Locale\" FROM \"allhsgrades24\".\"tbl_approvedschools\"', engine)\n",
    "\n",
    "\n",
    "# join locale into gadoe\n",
    "gadoe = gadoe.merge(approved, on=\"UNIQUESCHOOLID\", how=\"left\")\n",
    "\n",
    "# categorize RI values\n",
    "def categorize_ri(val):\n",
    "    if pd.isna(val):\n",
    "        return \"Missing\"\n",
    "    elif val > 0.05:\n",
    "        return \"Overrepresented\"\n",
    "    elif val < -0.05:\n",
    "        return \"Underrepresented\"\n",
    "    else:\n",
    "        return \"Parity\"\n",
    "\n",
    "# function to generate formatted summary table\n",
    "def formatted_disparity_table(df, ri_col, race_label):\n",
    "    df = df.copy()\n",
    "    df[\"Category\"] = df[ri_col].apply(categorize_ri)\n",
    "\n",
    "    # build locale-wise summary\n",
    "    summary = df.groupby(\"Locale\").agg({\n",
    "        \"Category\": [\n",
    "            (\"Overrepresentation (School Count)\", lambda x: (x == \"Overrepresented\").sum()),\n",
    "            (\"Parity (School Count)\", lambda x: (x == \"Parity\").sum()),\n",
    "            (\"Underrepresentation (School Count)\", lambda x: (x == \"Underrepresented\").sum())\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # flatten multi-index columns\n",
    "    summary.columns = [col[1] if isinstance(col, tuple) else col for col in summary.columns]\n",
    "    summary = summary.rename(columns={ri_col: \"Overall Disparity (Mean Â± Std)\"})\n",
    "    summary = summary.reset_index()\n",
    "    summary.insert(0, \"Locale Type\", summary.pop(\"Locale\"))\n",
    "\n",
    "    # compute total values\n",
    "    total_row = {\n",
    "        \"Locale Type\": \"Total\",\n",
    "        \"Overrepresentation (School Count)\": (df[\"Category\"] == \"Overrepresented\").sum(),\n",
    "        \"Parity (School Count)\": (df[\"Category\"] == \"Parity\").sum(),\n",
    "        \"Underrepresentation (School Count)\": (df[\"Category\"] == \"Underrepresented\").sum()\n",
    "    }\n",
    "\n",
    "    summary = pd.concat([summary, pd.DataFrame([total_row])], ignore_index=True)\n",
    "    return summary\n",
    "\n",
    "asian_table = formatted_disparity_table(gadoe, \"RI_Asian\", \"Asian\")\n",
    "display(asian_table.style.set_caption(\"Asian\"))\n",
    "\n",
    "black_table = formatted_disparity_table(gadoe, \"RI_Black\", \"Black\")\n",
    "display(black_table.style.set_caption(\"Black\"))\n",
    "\n",
    "hispanic_table = formatted_disparity_table(gadoe, \"RI_Hispanic\", \"Hispanic\")\n",
    "display(hispanic_table.style.set_caption(\"Hispanic\"))\n",
    "\n",
    "white_table = formatted_disparity_table(gadoe, \"RI_White\", \"White\")\n",
    "display(white_table.style.set_caption(\"White\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d5204",
   "metadata": {},
   "source": [
    "## Add Lunch Data to tbl_approvedschools\n",
    "Import lunch program data from CSV and add it to the approved schools table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "814655d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 468060 records from lunch data CSV\n",
      "Columns: ['SCHOOL_YEAR', 'FIPST', 'STATENAME', 'ST', 'SCH_NAME', 'STATE_AGENCY_NO', 'UNION', 'ST_LEAID', 'LEAID', 'ST_SCHID', 'NCESSCH', 'SCHID', 'DATA_GROUP', 'LUNCH_PROGRAM', 'STUDENT_COUNT', 'TOTAL_INDICATOR', 'DMS_FLAG']\n",
      "Georgia schools with Education Unit Total: 4626\n",
      "Unique DATA_GROUP values: ['Free and Reduced-price Lunch Table' 'Direct Certification']\n",
      "Georgia schools with Direct Certification: 2313\n",
      "Georgia schools with Free and Reduced-price Lunch Table: 2313\n",
      "Unique schools in lunch data: 2313\n",
      "Sample of cleaned data:\n",
      "  UNIQUESCHOOLID_CLEAN  lunch_student_count  lunch_student_eligible  \\\n",
      "0             06010103                382.0                   695.0   \n",
      "1             06010177                528.0                  1138.0   \n",
      "2             06010195                315.0                   615.0   \n",
      "3             06011050                123.0                   246.0   \n",
      "4             06015050                 35.0                    73.0   \n",
      "\n",
      "                            SCH_NAME  \n",
      "0         Appling County High School  \n",
      "1   Appling County Elementary School  \n",
      "2       Appling County Middle School  \n",
      "3         Altamaha Elementary School  \n",
      "4  Fourth District Elementary School  \n",
      "\n",
      "Summary statistics:\n",
      "Direct Certification (lunch_student_count): mean=190.0, max=2007.0\n",
      "Eligible (lunch_student_eligible): mean=483.9, max=4609.0\n"
     ]
    }
   ],
   "source": [
    "# Load lunch data CSV\n",
    "lunch_csv_path = '/Users/linnerlek/Documents/nsf_cosea/tocepaperanalysis/sql/ccd_sch_033_2324_l_1a_073124.csv'\n",
    "lunch_data = pd.read_csv(lunch_csv_path)\n",
    "\n",
    "print(f\"Loaded {len(lunch_data)} records from lunch data CSV\")\n",
    "print(f\"Columns: {lunch_data.columns.tolist()}\")\n",
    "\n",
    "# Filter for Georgia schools with Education Unit Total\n",
    "ga_lunch_base = lunch_data[\n",
    "    (lunch_data['ST'] == 'GA') & \n",
    "    (lunch_data['TOTAL_INDICATOR'] == 'Education Unit Total')\n",
    "].copy()\n",
    "\n",
    "print(f\"Georgia schools with Education Unit Total: {len(ga_lunch_base)}\")\n",
    "\n",
    "# Check unique DATA_GROUP values\n",
    "print(f\"Unique DATA_GROUP values: {ga_lunch_base['DATA_GROUP'].unique()}\")\n",
    "\n",
    "# Filter for Direct Certification (actual lunch participants)\n",
    "ga_lunch_direct = ga_lunch_base[\n",
    "    ga_lunch_base['DATA_GROUP'] == 'Direct Certification'\n",
    "].copy()\n",
    "\n",
    "# Filter for Free and Reduced-price Lunch Table (eligible students)\n",
    "ga_lunch_eligible = ga_lunch_base[\n",
    "    ga_lunch_base['DATA_GROUP'] == 'Free and Reduced-price Lunch Table'\n",
    "].copy()\n",
    "\n",
    "print(f\"Georgia schools with Direct Certification: {len(ga_lunch_direct)}\")\n",
    "print(f\"Georgia schools with Free and Reduced-price Lunch Table: {len(ga_lunch_eligible)}\")\n",
    "\n",
    "# Clean the ST_SCHID to create UNIQUESCHOOLID\n",
    "def clean_school_id(st_schid):\n",
    "    \"\"\"Convert GA-741-0191 to 07410191\"\"\"\n",
    "    if pd.isna(st_schid):\n",
    "        return None\n",
    "    # Remove GA- prefix and all non-numeric characters\n",
    "    cleaned = st_schid.replace('GA-', '').replace('-', '').replace(' ', '')\n",
    "    # Keep only numeric characters\n",
    "    numeric_only = ''.join(c for c in cleaned if c.isdigit())\n",
    "    # Pad with leading zero to make 8 digits\n",
    "    return numeric_only.zfill(8)\n",
    "\n",
    "# Process Direct Certification data (lunch_student_count)\n",
    "ga_lunch_direct['UNIQUESCHOOLID_CLEAN'] = ga_lunch_direct['ST_SCHID'].apply(clean_school_id)\n",
    "lunch_direct_aggregated = ga_lunch_direct.groupby(['UNIQUESCHOOLID_CLEAN', 'SCH_NAME'])['STUDENT_COUNT'].sum().reset_index()\n",
    "lunch_direct_aggregated.rename(columns={'STUDENT_COUNT': 'lunch_student_count'}, inplace=True)\n",
    "\n",
    "# Process Free and Reduced-price Lunch Table data (lunch_student_eligible)\n",
    "ga_lunch_eligible['UNIQUESCHOOLID_CLEAN'] = ga_lunch_eligible['ST_SCHID'].apply(clean_school_id)\n",
    "lunch_eligible_aggregated = ga_lunch_eligible.groupby(['UNIQUESCHOOLID_CLEAN', 'SCH_NAME'])['STUDENT_COUNT'].sum().reset_index()\n",
    "lunch_eligible_aggregated.rename(columns={'STUDENT_COUNT': 'lunch_student_eligible'}, inplace=True)\n",
    "\n",
    "# Merge both datasets\n",
    "lunch_aggregated = pd.merge(\n",
    "    lunch_direct_aggregated[['UNIQUESCHOOLID_CLEAN', 'lunch_student_count']], \n",
    "    lunch_eligible_aggregated[['UNIQUESCHOOLID_CLEAN', 'lunch_student_eligible']], \n",
    "    on='UNIQUESCHOOLID_CLEAN', \n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Add school name back\n",
    "school_names_lookup = ga_lunch_base.drop_duplicates('ST_SCHID')[['ST_SCHID', 'SCH_NAME']].copy()\n",
    "school_names_lookup['UNIQUESCHOOLID_CLEAN'] = school_names_lookup['ST_SCHID'].apply(clean_school_id)\n",
    "lunch_aggregated = pd.merge(\n",
    "    lunch_aggregated,\n",
    "    school_names_lookup[['UNIQUESCHOOLID_CLEAN', 'SCH_NAME']],\n",
    "    on='UNIQUESCHOOLID_CLEAN',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Unique schools in lunch data: {len(lunch_aggregated)}\")\n",
    "print(\"Sample of cleaned data:\")\n",
    "print(lunch_aggregated.head())\n",
    "print(f\"\\nSummary statistics:\")\n",
    "print(f\"Direct Certification (lunch_student_count): mean={lunch_aggregated['lunch_student_count'].mean():.1f}, max={lunch_aggregated['lunch_student_count'].max()}\")\n",
    "print(f\"Eligible (lunch_student_eligible): mean={lunch_aggregated['lunch_student_eligible'].mean():.1f}, max={lunch_aggregated['lunch_student_eligible'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00f69d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns may already exist: Not an executable object: '\\n            ALTER TABLE \"allhsgrades24\".tbl_approvedschools \\n            ADD COLUMN IF NOT EXISTS lunch_student_count INTEGER,\\n            ADD COLUMN IF NOT EXISTS lunch_student_eligible INTEGER\\n        '\n",
      "Current approved schools: 394\n",
      "\n",
      "Match Statistics:\n",
      "Total approved schools: 394\n",
      "Schools with Direct Certification data: 394\n",
      "Schools with Eligibility data: 394\n",
      "Direct Certification match percentage: 100.00%\n",
      "Eligibility match percentage: 100.00%\n",
      "\n",
      "Sample of schools WITH both types of data:\n",
      "  UNIQUESCHOOLID               SCHOOL_NAME  lunch_student_count  \\\n",
      "0       06600203     Northview High School                 37.0   \n",
      "1       06600176      Banneker High School                662.0   \n",
      "2       06600119     Cambridge High School                 34.0   \n",
      "3       06600106        Milton High School                 72.0   \n",
      "4       06942060  Macon County High School                 98.0   \n",
      "\n",
      "   lunch_student_eligible  \n",
      "0                   246.0  \n",
      "1                  1786.0  \n",
      "2                   181.0  \n",
      "3                   350.0  \n",
      "4                   262.0  \n",
      "\n",
      "Sample of schools WITHOUT any lunch data:\n",
      "Empty DataFrame\n",
      "Columns: [UNIQUESCHOOLID, SCHOOL_NAME]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Add both lunch_student_count and lunch_student_eligible columns to tbl_approvedschools if they don't exist\n",
    "try:\n",
    "    # Try to add both columns (will fail silently if they already exist)\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(\"\"\"\n",
    "            ALTER TABLE \"allhsgrades24\".tbl_approvedschools \n",
    "            ADD COLUMN IF NOT EXISTS lunch_student_count INTEGER,\n",
    "            ADD COLUMN IF NOT EXISTS lunch_student_eligible INTEGER\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "    print(\"Added lunch_student_count and lunch_student_eligible columns to tbl_approvedschools\")\n",
    "except Exception as e:\n",
    "    print(f\"Columns may already exist: {e}\")\n",
    "\n",
    "# Load current approved schools data\n",
    "current_approved = pd.read_sql('SELECT \"UNIQUESCHOOLID\", \"SCHOOL_NAME\" FROM \"allhsgrades24\".\"tbl_approvedschools\"', engine)\n",
    "print(f\"Current approved schools: {len(current_approved)}\")\n",
    "\n",
    "# Merge lunch data with approved schools\n",
    "merged_lunch = pd.merge(\n",
    "    current_approved, \n",
    "    lunch_aggregated[['UNIQUESCHOOLID_CLEAN', 'lunch_student_count', 'lunch_student_eligible']], \n",
    "    left_on='UNIQUESCHOOLID', \n",
    "    right_on='UNIQUESCHOOLID_CLEAN', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Count matches and misses\n",
    "lunch_matches = merged_lunch['lunch_student_count'].notna().sum()\n",
    "eligible_matches = merged_lunch['lunch_student_eligible'].notna().sum()\n",
    "total = len(merged_lunch)\n",
    "\n",
    "print(f\"\\nMatch Statistics:\")\n",
    "print(f\"Total approved schools: {total}\")\n",
    "print(f\"Schools with Direct Certification data: {lunch_matches}\")\n",
    "print(f\"Schools with Eligibility data: {eligible_matches}\")\n",
    "print(f\"Direct Certification match percentage: {(lunch_matches/total)*100:.2f}%\")\n",
    "print(f\"Eligibility match percentage: {(eligible_matches/total)*100:.2f}%\")\n",
    "\n",
    "# Show sample of matched schools\n",
    "print(f\"\\nSample of schools WITH both types of data:\")\n",
    "sample_matched = merged_lunch[(merged_lunch['lunch_student_count'].notna()) & (merged_lunch['lunch_student_eligible'].notna())].head()\n",
    "print(sample_matched[['UNIQUESCHOOLID', 'SCHOOL_NAME', 'lunch_student_count', 'lunch_student_eligible']])\n",
    "\n",
    "# Show sample of unmatched schools\n",
    "print(f\"\\nSample of schools WITHOUT any lunch data:\")\n",
    "sample_unmatched = merged_lunch[(merged_lunch['lunch_student_count'].isna()) & (merged_lunch['lunch_student_eligible'].isna())].head()\n",
    "print(sample_unmatched[['UNIQUESCHOOLID', 'SCHOOL_NAME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccbe02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns added successfully\n",
      "\n",
      "Preparing to update 394 schools\n",
      "Batch 1: Updated 50 schools\n",
      "Batch 2: Updated 50 schools\n",
      "Batch 3: Updated 50 schools\n",
      "Batch 4: Updated 50 schools\n",
      "Batch 5: Updated 50 schools\n",
      "Batch 6: Updated 50 schools\n",
      "Batch 7: Updated 50 schools\n",
      "Batch 8: Updated 44 schools\n",
      "\n",
      "Successfully updated 394 schools with lunch and eligibility data\n",
      "\n",
      "Final verification:\n",
      "   total_schools  schools_with_lunch_data  schools_with_eligible_data  \\\n",
      "0            394                      394                         394   \n",
      "\n",
      "   min_lunch_count  max_lunch_count  avg_lunch_count  min_eligible  \\\n",
      "0                0              954       273.393401             0   \n",
      "\n",
      "   max_eligible  avg_eligible  \n",
      "0          2511    741.243655  \n",
      "\n",
      "Top 10 schools by eligibility (with participation rates):\n",
      "  UNIQUESCHOOLID                 SCHOOL_NAME  lunch_student_count  \\\n",
      "0       06671050         Berkmar High School                  605   \n",
      "1       06332066         Osborne High School                  662   \n",
      "2       06670187     Meadowcreek High School                  656   \n",
      "3       06334066     Pebblebrook High School                  697   \n",
      "4       06671814       Discovery High School                  515   \n",
      "5       07920273        Valdosta High School                  871   \n",
      "6       07070173          Newton High School                  600   \n",
      "7       06670176        Parkview High School                  428   \n",
      "8       06672558  South Gwinnett High School                  605   \n",
      "9       06670101         Grayson High School                  484   \n",
      "\n",
      "   lunch_student_eligible  Locale  participation_rate_pct  \n",
      "0                    2511  Suburb                    24.1  \n",
      "1                    2362  Suburb                    28.0  \n",
      "2                    2272  Suburb                    28.9  \n",
      "3                    2114  Suburb                    33.0  \n",
      "4                    2110  Suburb                    24.4  \n",
      "5                    2102   Rural                    41.4  \n",
      "6                    1936  Suburb                    31.0  \n",
      "7                    1920  Suburb                    22.3  \n",
      "8                    1913  Suburb                    31.6  \n",
      "9                    1894  Suburb                    25.6  \n"
     ]
    }
   ],
   "source": [
    "# Update the database table with both lunch data columns using pandas approach\n",
    "from sqlalchemy import text\n",
    "\n",
    "# First, let's verify we can add both columns\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE allhsgrades24.tbl_approvedschools \n",
    "            ADD COLUMN IF NOT EXISTS lunch_student_count INTEGER,\n",
    "            ADD COLUMN IF NOT EXISTS lunch_student_eligible INTEGER\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "    print(\"Columns added successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Columns likely already exist: {e}\")\n",
    "\n",
    "# Create a DataFrame with updates for both columns\n",
    "updates_df = merged_lunch[\n",
    "    (merged_lunch['lunch_student_count'].notna()) | (merged_lunch['lunch_student_eligible'].notna())\n",
    "][['UNIQUESCHOOLID', 'lunch_student_count', 'lunch_student_eligible']].copy()\n",
    "\n",
    "# Fill NaN values with 0 for the update\n",
    "updates_df['lunch_student_count'] = updates_df['lunch_student_count'].fillna(0)\n",
    "updates_df['lunch_student_eligible'] = updates_df['lunch_student_eligible'].fillna(0)\n",
    "\n",
    "print(f\"\\nPreparing to update {len(updates_df)} schools\")\n",
    "\n",
    "# Use pandas to update in batches - more efficient approach\n",
    "update_count = 0\n",
    "batch_size = 50\n",
    "\n",
    "for i in range(0, len(updates_df), batch_size):\n",
    "    batch = updates_df.iloc[i:i+batch_size]\n",
    "    \n",
    "    # Create a series of WHEN-THEN statements for batch update of both columns\n",
    "    lunch_when_statements = []\n",
    "    eligible_when_statements = []\n",
    "    school_ids = []\n",
    "    \n",
    "    for _, row in batch.iterrows():\n",
    "        lunch_count = int(row['lunch_student_count']) if pd.notnull(row['lunch_student_count']) else 0\n",
    "        eligible_count = int(row['lunch_student_eligible']) if pd.notnull(row['lunch_student_eligible']) else 0\n",
    "        \n",
    "        lunch_when_statements.append(f\"WHEN '{row['UNIQUESCHOOLID']}' THEN {lunch_count}\")\n",
    "        eligible_when_statements.append(f\"WHEN '{row['UNIQUESCHOOLID']}' THEN {eligible_count}\")\n",
    "        school_ids.append(f\"'{row['UNIQUESCHOOLID']}'\")\n",
    "    \n",
    "    # Create the batch update SQL for both columns\n",
    "    sql_update = f\"\"\"\n",
    "    UPDATE allhsgrades24.tbl_approvedschools \n",
    "    SET \n",
    "        lunch_student_count = CASE \"UNIQUESCHOOLID\"\n",
    "            {' '.join(lunch_when_statements)}\n",
    "            ELSE lunch_student_count\n",
    "        END,\n",
    "        lunch_student_eligible = CASE \"UNIQUESCHOOLID\"\n",
    "            {' '.join(eligible_when_statements)}\n",
    "            ELSE lunch_student_eligible\n",
    "        END\n",
    "    WHERE \"UNIQUESCHOOLID\" IN ({', '.join(school_ids)})\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_update))\n",
    "            conn.commit()\n",
    "            update_count += result.rowcount\n",
    "            print(f\"Batch {i//batch_size + 1}: Updated {result.rowcount} schools\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {i//batch_size + 1}: {e}\")\n",
    "\n",
    "print(f\"\\nSuccessfully updated {update_count} schools with lunch and eligibility data\")\n",
    "\n",
    "# Verify the update\n",
    "verification = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_schools,\n",
    "        COUNT(lunch_student_count) as schools_with_lunch_data,\n",
    "        COUNT(lunch_student_eligible) as schools_with_eligible_data,\n",
    "        MIN(lunch_student_count) as min_lunch_count,\n",
    "        MAX(lunch_student_count) as max_lunch_count,\n",
    "        AVG(lunch_student_count) as avg_lunch_count,\n",
    "        MIN(lunch_student_eligible) as min_eligible,\n",
    "        MAX(lunch_student_eligible) as max_eligible,\n",
    "        AVG(lunch_student_eligible) as avg_eligible\n",
    "    FROM allhsgrades24.tbl_approvedschools\n",
    "    WHERE lunch_student_count IS NOT NULL OR lunch_student_eligible IS NOT NULL\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nFinal verification:\")\n",
    "print(verification)\n",
    "\n",
    "# Show comparison of top 10 schools by both metrics - Fixed ROUND function for PostgreSQL\n",
    "comparison = pd.read_sql(\"\"\"\n",
    "    SELECT \"UNIQUESCHOOLID\", \"SCHOOL_NAME\", lunch_student_count, lunch_student_eligible, \"Locale\",\n",
    "           CASE \n",
    "               WHEN lunch_student_eligible > 0 THEN ROUND(CAST((lunch_student_count * 100.0 / lunch_student_eligible) AS NUMERIC), 1)\n",
    "               ELSE NULL \n",
    "           END as participation_rate_pct\n",
    "    FROM allhsgrades24.tbl_approvedschools \n",
    "    WHERE lunch_student_count IS NOT NULL AND lunch_student_eligible IS NOT NULL\n",
    "        AND (lunch_student_count > 0 OR lunch_student_eligible > 0)\n",
    "    ORDER BY lunch_student_eligible DESC\n",
    "    LIMIT 10\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nTop 10 schools by eligibility (with participation rates):\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8af7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunch Program Data Distribution:\n",
      "   total_schools  schools_with_zero_participants  schools_with_participants  \\\n",
      "0            394                               1                        393   \n",
      "\n",
      "   schools_no_participant_data  schools_with_zero_eligible  \\\n",
      "0                            0                           1   \n",
      "\n",
      "   schools_with_eligible  schools_no_eligible_data  \n",
      "0                    393                         0  \n",
      "\n",
      "Schools with 0 participants but eligible students (0 schools):\n",
      "No schools found with this pattern\n",
      "\n",
      "Participant vs Eligible Distribution (showing top combinations):\n",
      "       participant_range     eligible_range  school_count\n",
      "0   101-500 participants  501-1000 eligible           160\n",
      "1   101-500 participants   101-500 eligible            67\n",
      "2     1-100 participants   101-500 eligible            53\n",
      "3   101-500 participants     1000+ eligible            50\n",
      "4  501-1000 participants     1000+ eligible            43\n",
      "5     1-100 participants     1-100 eligible            16\n",
      "6     1-100 participants  501-1000 eligible             3\n",
      "7  501-1000 participants  501-1000 eligible             1\n",
      "8         0 participants         0 eligible             1\n",
      "\n",
      "Top 20 schools by participation rate (participants/eligible):\n",
      "   UNIQUESCHOOLID                     SCHOOL_NAME  participants  \\\n",
      "0        06390193     Crawford County High School           297   \n",
      "1        06190113      Calhoun County High School           135   \n",
      "2        07430201       Twiggs County High School           166   \n",
      "3        07423050       Turner County High School           261   \n",
      "4        07733050             Decatur High School           280   \n",
      "5        06290104        Classic City High School            29   \n",
      "6        06210101             Metter High School            238   \n",
      "7        06314058              Morrow High School           954   \n",
      "8        07520108      Webster County High School            29   \n",
      "9        07480195         Ware County High School           943   \n",
      "10       06131050     Brantley County High School           334   \n",
      "11       06810196    Jefferson County High School           316   \n",
      "12       06110204             Rutland High School           193   \n",
      "13       07280201      Stewart County High School            60   \n",
      "14       06311056           Jonesboro High School           669   \n",
      "15       06311054         Forest Park High School           785   \n",
      "16       07300190  Central Elementary/High School           233   \n",
      "17       07162050        Hawkinsville High School           140   \n",
      "18       06542050             Claxton High School           190   \n",
      "19       06110386           Southwest High School           311   \n",
      "\n",
      "    lunch_student_eligible  Locale  participation_rate_pct  \n",
      "0                      290   Rural                   102.4  \n",
      "1                      135   Rural                   100.0  \n",
      "2                      166   Rural                   100.0  \n",
      "3                      300    Town                    87.0  \n",
      "4                      330  Suburb                    84.8  \n",
      "5                       36    City                    80.6  \n",
      "6                      327   Rural                    72.8  \n",
      "7                     1328  Suburb                    71.8  \n",
      "8                       41   Rural                    70.7  \n",
      "9                     1360    Town                    69.3  \n",
      "10                     490   Rural                    68.2  \n",
      "11                     477   Rural                    66.2  \n",
      "12                     311    City                    62.1  \n",
      "13                      97   Rural                    61.9  \n",
      "14                    1092  Suburb                    61.3  \n",
      "15                    1284  Suburb                    61.1  \n",
      "16                     390   Rural                    59.7  \n",
      "17                     236    Town                    59.3  \n",
      "18                     323   Rural                    58.8  \n",
      "19                     530    City                    58.7  \n"
     ]
    }
   ],
   "source": [
    "# Check distribution of both lunch program metrics\n",
    "lunch_summary = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_schools,\n",
    "        COUNT(CASE WHEN lunch_student_count = 0 THEN 1 END) as schools_with_zero_participants,\n",
    "        COUNT(CASE WHEN lunch_student_count > 0 THEN 1 END) as schools_with_participants,\n",
    "        COUNT(CASE WHEN lunch_student_count IS NULL THEN 1 END) as schools_no_participant_data,\n",
    "        COUNT(CASE WHEN lunch_student_eligible = 0 THEN 1 END) as schools_with_zero_eligible,\n",
    "        COUNT(CASE WHEN lunch_student_eligible > 0 THEN 1 END) as schools_with_eligible,\n",
    "        COUNT(CASE WHEN lunch_student_eligible IS NULL THEN 1 END) as schools_no_eligible_data\n",
    "    FROM allhsgrades24.tbl_approvedschools\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"Lunch Program Data Distribution:\")\n",
    "print(lunch_summary)\n",
    "\n",
    "# Show schools with 0 participants but eligible students (potential underparticipation)\n",
    "underparticipation = pd.read_sql(\"\"\"\n",
    "    SELECT \"UNIQUESCHOOLID\", \"SCHOOL_NAME\", lunch_student_count, lunch_student_eligible, \"Locale\", \"SYSTEM_NAME\"\n",
    "    FROM allhsgrades24.tbl_approvedschools \n",
    "    WHERE lunch_student_count = 0 AND lunch_student_eligible > 0\n",
    "    ORDER BY lunch_student_eligible DESC\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nSchools with 0 participants but eligible students ({len(underparticipation)} schools):\")\n",
    "if len(underparticipation) > 0:\n",
    "    print(underparticipation)\n",
    "else:\n",
    "    print(\"No schools found with this pattern\")\n",
    "\n",
    "# Distribution comparison\n",
    "participation_distribution = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN lunch_student_count = 0 THEN '0 participants'\n",
    "            WHEN lunch_student_count BETWEEN 1 AND 100 THEN '1-100 participants'\n",
    "            WHEN lunch_student_count BETWEEN 101 AND 500 THEN '101-500 participants'\n",
    "            WHEN lunch_student_count BETWEEN 501 AND 1000 THEN '501-1000 participants'\n",
    "            WHEN lunch_student_count > 1000 THEN '1000+ participants'\n",
    "            ELSE 'No participant data'\n",
    "        END as participant_range,\n",
    "        CASE \n",
    "            WHEN lunch_student_eligible = 0 THEN '0 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 1 AND 100 THEN '1-100 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 101 AND 500 THEN '101-500 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 501 AND 1000 THEN '501-1000 eligible'\n",
    "            WHEN lunch_student_eligible > 1000 THEN '1000+ eligible'\n",
    "            ELSE 'No eligible data'\n",
    "        END as eligible_range,\n",
    "        COUNT(*) as school_count\n",
    "    FROM allhsgrades24.tbl_approvedschools\n",
    "    GROUP BY \n",
    "        CASE \n",
    "            WHEN lunch_student_count = 0 THEN '0 participants'\n",
    "            WHEN lunch_student_count BETWEEN 1 AND 100 THEN '1-100 participants'\n",
    "            WHEN lunch_student_count BETWEEN 101 AND 500 THEN '101-500 participants'\n",
    "            WHEN lunch_student_count BETWEEN 501 AND 1000 THEN '501-1000 participants'\n",
    "            WHEN lunch_student_count > 1000 THEN '1000+ participants'\n",
    "            ELSE 'No participant data'\n",
    "        END,\n",
    "        CASE \n",
    "            WHEN lunch_student_eligible = 0 THEN '0 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 1 AND 100 THEN '1-100 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 101 AND 500 THEN '101-500 eligible'\n",
    "            WHEN lunch_student_eligible BETWEEN 501 AND 1000 THEN '501-1000 eligible'\n",
    "            WHEN lunch_student_eligible > 1000 THEN '1000+ eligible'\n",
    "            ELSE 'No eligible data'\n",
    "        END\n",
    "    ORDER BY school_count DESC\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nParticipant vs Eligible Distribution (showing top combinations):\")\n",
    "print(participation_distribution.head(15))\n",
    "\n",
    "# Calculate participation rates - Fixed ROUND function for PostgreSQL\n",
    "participation_rates = pd.read_sql(\"\"\"\n",
    "    SELECT \n",
    "        \"UNIQUESCHOOLID\", \n",
    "        \"SCHOOL_NAME\", \n",
    "        lunch_student_count as participants, \n",
    "        lunch_student_eligible,\n",
    "        \"Locale\",\n",
    "        CASE \n",
    "            WHEN lunch_student_eligible > 0 THEN ROUND(CAST((lunch_student_count * 100.0 / lunch_student_eligible) AS NUMERIC), 1)\n",
    "            ELSE NULL \n",
    "        END as participation_rate_pct\n",
    "    FROM allhsgrades24.tbl_approvedschools \n",
    "    WHERE lunch_student_count IS NOT NULL AND lunch_student_eligible IS NOT NULL AND lunch_student_eligible > 0\n",
    "    ORDER BY participation_rate_pct DESC NULLS LAST\n",
    "    LIMIT 20\n",
    "\"\"\", engine)\n",
    "\n",
    "print(f\"\\nTop 20 schools by participation rate (participants/eligible):\")\n",
    "print(participation_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d90a981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed old 'eligible' column from tbl_approvedschools\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sqlalchemy.cyextension.immutabledict.immutabledict is not a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError removing column (may not exist): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Verify the current columns in the table\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m current_columns \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43m    SELECT column_name \u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;43m    FROM information_schema.columns \u001b[39;49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;43m    WHERE table_name = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtbl_approvedschools\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;43m        AND table_schema = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallhsgrades24\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43m        AND column_name LIKE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%lu\u001b[39;49;00m\u001b[38;5;124;43mnch\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43m    ORDER BY column_name\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCurrent lunch-related columns in tbl_approvedschools:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m current_columns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:734\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    725\u001b[0m         sql,\n\u001b[1;32m    726\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    731\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    732\u001b[0m     )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:1836\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   1780\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1781\u001b[0m     sql: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1788\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1789\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;124;03m    Read SQL query into a DataFrame.\u001b[39;00m\n\u001b[1;32m   1792\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m \n\u001b[1;32m   1835\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1836\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1837\u001b[0m     columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/sql.py:1659\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   1657\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sql, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1776\u001b[0m, in \u001b[0;36mConnection.exec_driver_sql\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1771\u001b[0m execution_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_options\u001b[38;5;241m.\u001b[39mmerge_with(\n\u001b[1;32m   1772\u001b[0m     execution_options\n\u001b[1;32m   1773\u001b[0m )\n\u001b[1;32m   1775\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[0;32m-> 1776\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1843\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1983\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1980\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1983\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1984\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2354\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2357\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/base.py:1964\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1962\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1964\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1970\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1971\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1976\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sqlalchemy/engine/default.py:945\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 945\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sqlalchemy.cyextension.immutabledict.immutabledict is not a sequence"
     ]
    }
   ],
   "source": [
    "# Remove the old 'eligible' column if it exists\n",
    "from sqlalchemy import text\n",
    "\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            ALTER TABLE allhsgrades24.tbl_approvedschools \n",
    "            DROP COLUMN IF EXISTS eligible\n",
    "        \"\"\"))\n",
    "        conn.commit()\n",
    "    print(\"Successfully removed old 'eligible' column from tbl_approvedschools\")\n",
    "except Exception as e:\n",
    "    print(f\"Error removing column (may not exist): {e}\")\n",
    "\n",
    "# Verify the current columns in the table\n",
    "current_columns = pd.read_sql(\"\"\"\n",
    "    SELECT column_name \n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = 'tbl_approvedschools' \n",
    "        AND table_schema = 'allhsgrades24'\n",
    "        AND column_name LIKE '%lunch%'\n",
    "    ORDER BY column_name\n",
    "\"\"\", engine)\n",
    "\n",
    "print(\"\\nCurrent lunch-related columns in tbl_approvedschools:\")\n",
    "for col in current_columns['column_name']:\n",
    "    print(f\"  - {col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
